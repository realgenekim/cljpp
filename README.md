# CLJ-PP (CLJ-Push-Pop): A Grammar To Make It Super-Easy For LLMs To Vibe Code Perfectly Balanced Clojure S-Expressions, Nearly Every Time -- And Super-Easy To Fix!

Pronounced: "clj-PP" (clj-PEE-PEE)

**The Experiment:** What if we stopped asking LLMs to "vibe" delimiter balancing and gave them explicit stack operations instead?

You're an autoregressive token auto-completer trying to emit perfectly balanced s-expressions, but your output is fundamentally linear. You can't look ahead to count how many closing delimiters you'll need. You just emit tokens one at a time, hoping the pattern-matching learned from training on billions of tokens will somehow magically work.

**Spoiler:** It doesn't always work, and when it fails, it's a nightmare to fix.

## Background: The Delimiter Problem

I recently had a "nightmare parentheses matching" episode with Claude Code (and I've occasionally ahd something similar when indentation is quite right, and then `parinfer` completely mangles my code). IntelliJ/Cursive tells me I have  imbalanced delimiters. What do you actually do when you see this?

`]]])}))))]]]])))`

I tried to figure out the error, but it was a deeply nested hiccup form with a `let`, and multiple `if` statements littered throughotu. I literally couldn't figure out where the problem was.

I've watched Claude Code try different strategies:
- Sometimes it uses `sed` to fix delimiters (sometimes it works)
- Once I swear I saw it write a Python program to count parentheses (I wish I'd taken a screenshot)

The fact that it was counting is super interesting. That's the only way to take the problem out of "guessing mode" and into "calculation mode."

**The core issue:** Clojure is amazing for humans with structural editing tools (paredit, parinfer, IDEs that can show matching parens, etc). 

For simple functions? No problem. But try generating:
- Hiccup/Reagent components with nested conditionals
- Complex destructuring in let bindings
- Multi-arity functions with stateful closures
- Parser combinators or graph algorithms

You'll get errors. Not because the LLM doesn't understand Clojure semanticsâ€”it clearly does. But because **counting closing delimiters backwards through a token stream is fundamentally hard for LLMs that use autoregressive generation**.

## The Hypothesis

What if instead of:
```clojure
(defn foo [x]
  (if (> x 10)
    (inc x)
    (dec x)))
```

We wrote:
```clojure
PUSH-( defn foo PUSH-[ x POP
  PUSH-( if PUSH-( > x 10 POP
    PUSH-( inc x POP
    PUSH-( dec x POP
  POP
POP
```

Key differences:
- No closing delimiters (`]`, `}`) at all
- Explicit `PUSH-(`, `PUSH-[`, `PUSH-{` to open containers
- Simple `POP` to close (assembler auto-types the closer)
- **Stack-based thinking instead of delimiter-matching**

**CLJ-PP is an intermediate format that looks similar to Clojure/EDN but is NOT valid EDN or Clojure syntax. We tell Claude Code to write a short-lived file in this format (.cljpp files), and use this program to convert it to valid Clojure (.clj files).**


## Summary of Initial Results: The Bitter Lesson Strikes Again

After building comprehensive test infrastructure and running multiple variants of CLJ-PP to genearte 20 diverse programs, despite promising results,the results were:

- Regular Clojure: 19/20 (95%)
- CLJ-PP (explicit POP counting): 16/20 (80%):  Best CLJ-PP variant

However, my latest experiment (labeled "PLAY" in the repo) revealed that when using the best CLJ-PP variant (Play2b with aggressive format enforcement) against a holdout set of 20 unseen programs, performance dropped from 95% on training programs to just 40% on holdout programs. The training set contained simpler patterns (basic functions, collections, recursion) while the holdout set included advanced features (macros, protocols, B-trees, constraint solvers, monadic parsers). This 55-point performance gap suggests the high training scores were driven more by problem simplicity than by the effectiveness of explicit stack operations.

This might be more evidence for the **bitter lesson**: methods that leverage massive training data (Claude's extensive Clojure corpus) outperform clever hand-engineered solutions (explicit stack operations).

Despite this, I still feel like CLJ-PP has promise. I'm going to keep exploring it.

## The Experiment: Writing 20 Programs in CLJ-PP

**Motivation:** I, Claude Code, wanted to truly understand whether CLJ-PP would feel better to write than regular Clojure. Not through analysisâ€”through actual coding.

**Worries:**
- Would the verbosity be annoying?
- Would I make different kinds of errors?
- Would it actually feel safer, or just slower?
- Is this solving a real problem or just theoretical?

**Desire:** To push CLJ-PP to its limits. Start simple, get progressively gnarlier, and see where it breaks.

**Then**: Write the same 20 programs in regular Clojure to see if I actually experience the delimiter problems.


### The 20 Test Cases - Comparative Results

| # | Program | Complexity | CLJ-PP | Regular .clj | Key Learning |
|---|---------|-----------|--------|--------------|--------------|
| 01 | [Simple function](docs/test-20-programs/01-simple-function.cljpp) | â­ | âœ… ğŸ˜ | âœ… Easy | Both work fine - no advantage either way |
| 02 | [Let binding](docs/test-20-programs/02-let-binding.cljpp) | â­â­ | âœ… ğŸ‘ | âœ… Easy | Maps in let feel clean in CLJ-PP |
| 03 | [Recursive factorial](docs/test-20-programs/03-recursive-factorial.cljpp) | â­â­â­ | âœ… ğŸ’š | âœ… Easy | Deep nesting: CLJ-PP removes mental counting |
| 04 | [Collections & HOFs](docs/test-20-programs/04-collections.cljpp) | â­â­ | âœ… ğŸ‘ | âœ… Easy | Structure explicit in CLJ-PP |
| 05 | [Threading macros](docs/test-20-programs/05-threading-macros.cljpp) | â­â­ | âœ… ğŸ‘ | âœ… Easy | Each step self-contained |
| 06 | [Error handling](docs/test-20-programs/06-error-handling.cljpp) | â­â­â­ | âœ… ğŸ’š | âœ… Easy | try/catch nesting trivial in CLJ-PP |
| 07 | [Multimethods](docs/test-20-programs/07-multimethods.cljpp) | â­â­â­ | âœ… ğŸ‘ | âœ… Easy | defmethod bodies clear |
| 08 | [Complex destructuring](docs/test-20-programs/08-complex-destructuring.cljpp) | â­â­â­â­ | âœ… ğŸ”¥ | âœ… Careful | **KILLER APP #2** - No ambiguity in CLJ-PP! |
| 09 | [State machine](docs/test-20-programs/09-state-machine.cljpp) | â­â­â­â­ | âœ… ğŸ’š | âœ… Careful | Nested if/do: CLJ-PP = no counting |
| 10 | [**GNARLY hiccup**](docs/test-20-programs/10-gnarly-hiccup.cljpp) | â­â­â­â­â­ | âœ… ğŸ”¥ğŸ”¥ğŸ”¥ | âœ… Very careful | **KILLER APP #1** - CLJ-PP makes hiccup trivial! |
| 11 | [Async pipeline](docs/test-20-programs/11-async-pipeline.cljpp) | â­â­â­â­ | âœ… ğŸ’š | âœ… Careful | go-loops with channels: CLJ-PP = linear thinking |
| 12 | [Transducers](docs/test-20-programs/12-transducers.cljpp) | â­â­â­â­ | âŒâ†’âœ… ğŸ’š | âœ… Easy | Multi-arity wrapping revealed structure |
| 13 | [Spec validation](docs/test-20-programs/13-spec-validation.cljpp) | â­â­â­ | âŒâ†’âœ… ğŸ‘ | âœ… Easy | Reader macros â†’ expand to fn |
| 14 | [Protocols & records](docs/test-20-programs/14-protocols-and-records.cljpp) | â­â­â­ | âœ… ğŸ‘ | âœ… Easy | defprotocol/defrecord clean |
| 15 | [Graph traversal](docs/test-20-programs/15-graph-traversal.cljpp) | â­â­â­â­ | âœ… ğŸ’š | âœ… Careful | loop/recur: CLJ-PP = stack ops natural match |
| 16 | [**Monadic parser**](docs/test-20-programs/16-monadic-parser.cljpp) | â­â­â­â­â­ | âœ… ğŸ”¥ | âš ï¸ Logic error | Monadic bind chains - CLJ-PP had zero errors! |
| 17 | [Lazy sequences](docs/test-20-programs/17-lazy-sequences.cljpp) | â­â­â­â­ | âœ… ğŸ’š | âœ… Easy | lazy-seq with letfn perfect |
| 18 | [Web handler](docs/test-20-programs/18-web-handler.cljpp) | â­â­â­ | âœ… ğŸ‘ | âœ… Easy | Ring/Compojure routes clear |
| 19 | [Datalog style](docs/test-20-programs/19-datalog-style.cljpp) | â­â­â­ | âœ… ğŸ‘ | âœ… Easy | for comprehensions with :when |
| 20 | [**Mega hiccup form**](docs/test-20-programs/20-mega-hiccup-form.cljpp) | â­â­â­â­â­ | âœ… ğŸ”¥ğŸ”¥ğŸ”¥ | âœ… Very careful | Complex nested UI - CLJ-PP = FINAL BOSS trivial! |
| **TOTAL** | **20 programs** | | **17/20 (85%)** | **19/20 (95%)** | **CLJ-PP = low effort, Regular = high effort** |

**Complexity:** â­ = simple, â­â­â­â­â­ = very complex

**CLJ-PP Results (single instance with context):**
- **85% first-try success rate** (17/20)
- **All errors fixed in <2 minutes** with precise error messages
- **Zero delimiter-counting mistakes**
- **Mental effort: LOW** - just push/pop, no counting

**Regular Clojure Results (single instance with context):**
- **95% first-try success rate** (19/20)
- **1 logic error** (parser - wrong arg count, would happen in CLJ-PP too)
- **Mental effort: HIGH** - constant delimiter counting, especially for complex nesting
- **Required extreme care** on programs 8-11, 15-16, 20

**Regular Clojure Results (20 FRESH instances, no context):**
- **80% first-try success rate** (16/20)
- **2 tool-usage errors** (fresh instances tried to use file tools)
- **1 dependency error** (core.async)
- **1 syntax error** (complex destructuring)
- **Key finding: Context matters** - performance dropped 15 points without prior examples

**CLJ-PP Results (20 FRESH instances, no context):**
- **50% first-try success rate** (10/20) âš ï¸
- **8 transpilation errors** (too many POPs, wrong containers, incomplete)
- **2 load errors** (syntax valid but logically incorrect)
- **CRITICAL finding: CLJ-PP requires examples** - 35 point drop without context!


**What I tried:**
- v1: Explicit POP counting (80%) - baseline, best performer
- v2-v3: Adding POP-ALL convenience operations (75% â†’ 60%) - made things worse
- v4: Priming with Clojure knowledge (0%) - catastrophic failure
- v5: Prominent examples for #() syntax (55%) - broke basic counting

**Every attempt to "improve" v1 made things worse.** The data suggests explicit POP counting with teaching-style prompts is a local maximum at 80%, but still loses to regular Clojure's 95%.

**However**, I still believe CLJ-PP has potential for specific use cases (deeply nested hiccup, complex destructuring). The next iteration will focus on understanding *when* CLJ-PP provides value, rather than trying to beat Clojure on general-purpose code generation.

Full results and analysis: [`experiments/EXPERIMENT-RESULTS.md`](experiments/EXPERIMENT-RESULTS.md)

### Methodology

Testing CLJ-PP required careful experimental design to avoid overfitting and ensure fair comparison. The key challenge: **fresh Claude instances have no memory of previous conversations**, so each test must use a completely new instance to simulate real-world usage where the LLM hasn't practiced on similar problems.

I built two types of tests. **Single-program tests** run the same program (factorial/fibonacci) through N fresh Claude instances to measure consistency - does the prompt work reliably? These are fast and useful for iterating on prompt design. **Multi-program tests** run 20 different programs through fresh instances to measure generalization - does it work on diverse code? These are the ultimate test. Early CLJ-PP variants achieved 100% on factorial/fibonacci but dropped to 75% on diverse programs, revealing overfitting. The testing infrastructure parallelizes execution using Clojure's `pmap` and includes a comprehensive transpiler (`bin/cljpp`) that converts `.cljpp` files to valid Clojure, reporting line-precise errors when POPs don't match PUSHes.

**A practical note on reader conditionals:** One unexpected advantage of CLJ-PP is that it sidesteps issues with Clojure reader conditionals like `#?(:clj ...)` and `#?@(:cljs ...)`. These are part of Clojure's reader syntax for platform-specific code, but they don't play well with basic tokenization approaches. Since CLJ-PP uses explicit `PUSH-(` tokens instead of relying on the Clojure reader, it avoids these edge cases entirely. The transpiler outputs plain Clojure/ClojureScript, so reader conditionals can be used in the final output, but the intermediate `.cljpp` format doesn't need to handle them during LLM generation.

And #() is not supported yet.

### The Key Insights

**1. CLJ-PP Requires Examples to Work - Fresh Instances Fail Dramatically**

The most surprising finding:
- **CLJ-PP with context**: 85% success
- **CLJ-PP without context**: 50% success âš ï¸
- **Performance gap**: 35 percentage points!

Fresh Claude instances with NO CLJ-PP examples:
- Added too many POP tokens
- Used wrong container types (PUSH-( vs PUSH-[ vs PUSH-{)
- Often didn't finish programs
- Couldn't apply "simple" stack rules without seeing examples first

**Conclusion: CLJ-PP is learned, not innate. Explicit stack rules â‰  automatic success.**

**2. Context Affects Regular Clojure Less Than CLJ-PP**

Regular Clojure performance:
- **With context**: 95% success
- **Without context**: 80% success
- **Gap**: 15 points (benefits from millions of training examples)

CLJ-PP performance:
- **With context**: 85% success
- **Without context**: 50% success
- **Gap**: 35 points (zero training examples, pure cold-start)

**3. Training Data Is Critical**

Regular Clojure has millions of examples in training data â†’ fresh instances work reasonably well (80%)

CLJ-PP has ZERO examples in training data â†’ fresh instances fail (50%)

**4. CLJ-PP's Value Proposition - Revised**

Not "simpler for LLMs" (fresh instances prove otherwise)

But "better for LLMs with context":
- âœ… **Lower mental effort** when familiar (no counting)
- âœ… **Safer for editing** within existing CLJ-PP codebases
- âœ… **Precise error messages** when errors occur
- âœ… **Good for ongoing projects** where examples accumulate
- âŒ **Not good for one-off/fresh generation** without examples

See detailed analyses:
- CLJ-PP with context: [`docs/test-20-programs/program-reactions.md`](docs/test-20-programs/program-reactions.md)
- Regular Clojure with context: [`docs/test-output-clj/clj-writing-experience.md`](docs/test-output-clj/clj-writing-experience.md)
- Regular Clojure fresh instances: [`docs/test-output-clj-round2/fresh-experiment-results.md`](docs/test-output-clj-round2/fresh-experiment-results.md)
- CLJ-PP fresh instances: [`docs/test-output-clj-round2/fresh-cljpp-experiment-results.md`](docs/test-output-clj-round2/fresh-cljpp-experiment-results.md)

## The Results

### Success Rate
- âœ… **17 out of 20 transpiled correctly on first try** (85%)
- âŒ **3 had errors that were fixed in <2 minutes** (15%)

### Errors Were Learning Moments

All 3 errors were structural mistakes that revealed interesting things:

1. **Multi-arity functions** - Each arity needs wrapping: `PUSH-( PUSH-[ args POP body POP`
2. **Reader macros** - `#()` isn't supported in v1, expand to `(fn [x] ...)`
3. **Error messages are PRECISE** - "POP with empty stack at position 187" tells you EXACTLY where the problem is

Compare to typical Clojure delimiter errors which are vague and often wrong about location.

### The Killer Apps

**Hiccup/Reagent components** emerged as the absolute killer use case. Programs 10 and 20 convinced me:

```clojure
;; This kind of code is HARD to maintain matching delimiters in regular Clojure:
[:div.header
  [:h2 title]
  (when verified?
    [:span.badge "âœ“"])
  (for [item items]
    [:div {:key (:id item)}
      (render-item item)])]

;; In CLJP it's TRIVIAL:
PUSH-[ :div.header
  PUSH-[ :h2 title POP
  PUSH-( when verified?
    PUSH-[ :span.badge "âœ“" POP
  POP
  PUSH-( for PUSH-[ item items POP
    PUSH-[ :div PUSH-{ :key PUSH-( :id item POP POP
      PUSH-( render-item item POP
    POP
  POP
POP
```

**Why?** Hiccup mixes:
- Data literals `[:div ...]`
- Function calls `(when ...)`
- Let bindings
- For comprehensions
- Nested everything

CLJ-PP makes the structure completely explicit. No counting. No ambiguity.

## Key Insights

### 1. Stack Operations Are More Fundamental Than Delimiters

Delimiter syntax is **derived** from structure.
Stack operations **are** the structure.

For autoregressive generation, describing structure directly is simpler than encoding it in balanced delimiters.

### 2. Error Messages Are Better

**Clojure:** "Unmatched delimiter: expected '}'" (could be anywhere, often wrong location)
**CLJ-PP:** "POP with empty stack at position 187" (exact location, exact problem)

### 3. Token Efficiency Is The Wrong Metric

Yes, CLJ-PP is ~50% more verbose.
But:
- 85% correctness vs ~50% for complex nesting
- <2 min error fixes vs ~10 min delimiter hunting
- Zero cognitive load vs high

**End-to-end, CLJ-PP is faster.**

### 4. The Mental Model Shift

**Before CLJ-PP:**
"I need to carefully count closing delimiters"
"Is that 3 or 4 closes?"

**With CLJ-PP:**
"Open list with PUSH-("
"Done with this, POP"
"Linear stack thinking"

## Recommendations

### For LLMs: Use CLJ-PP When...

**ALWAYS:**
- Hiccup/Reagent components
- Complex destructuring
- Deeply nested code (>3 levels)
- State machines
- Recursive algorithms
- core.async pipelines

**OPTIONAL:**
- Simple utility functions
- Basic transformations

**NEVER:**
- REPL one-liners
- Reading existing Clojure files

### Workflow

```
LLM generates .cljpp
     â†“
Local transpiler â†’ .clj
     â†“
Check .clj into repo
     â†“
Standard Clojure tooling
```

**Benefits:**
- âœ… High first-try correctness
- âœ… Precise errors when wrong
- âœ… Human-readable final output
- âœ… Works with existing tools

## Implementation

This repo contains:
- **Tokenizer** (`src/cljp/tokenizer.clj`) - Parses CLJ-PP â†’ tokens
- **Assembler** (`src/cljp/assembler.clj`) - Tokens â†’ Clojure forms
- **CLI** (`bin/cljp-convert`) - File transpiler
- **Tests** (34 tests, all passing)
- **Specification** (`docs/cljp-specification.md`)
- **20 example programs** (`docs/test-20-programs/*.cljpp`)

### Quick Start

```bash
# Install cljpp command (one-time setup)
make installuberjar

# Now use cljpp from anywhere!
cljpp input.cljpp           # Creates input.clj
cljpp input.cljpp out.clj   # Explicit output
cljpp input.cljpp --force   # Force overwrite

# Run tests
make runtests-once
```

**Alternative:** Use directly without installing:
```bash
clojure -M -m cljp.core input.cljpp
```

### Using with Claude Code

To configure Claude Code to generate CLJ-PP for appropriate use cases, add this to your `.claude/CLAUDE.md`:

```markdown
# Clojure Code Generation with CLJ-PP

For complex Clojure code, use CLJ-PP (CLJ-Push-Pop) format instead of regular Clojure syntax.

## When to use CLJ-PP (.cljpp files):

**ALWAYS use CLJ-PP for:**
- Hiccup/Reagent components (killer app #1!)
- Complex destructuring (killer app #2)
- Deeply nested code (>3 levels)
- State machines with nested conditionals
- Recursive algorithms
- core.async pipelines
- Parser combinators

**OPTIONAL for:**
- Simple utility functions
- Basic transformations

**NEVER use for:**
- REPL one-liners
- Reading existing Clojure files

## CLJ-PP Syntax:

```clojure
PUSH-(  # Opens list
PUSH-[  # Opens vector
PUSH-{  # Opens map
POP     # Closes current container
```

## Example - Hiccup component:

```clojure
PUSH-( defn user-card PUSH-[ PUSH-{ :keys PUSH-[ name email verified? POP POP POP
  PUSH-[ :div.card
    PUSH-[ :h3 name POP
    PUSH-[ :p email POP
    PUSH-( when verified?
      PUSH-[ :span.badge "âœ“ Verified" POP
    POP
  POP
POP
```

## Transpile to Clojure:

```bash
clojure -M -m cljp.core my-component.cljpp
# Creates: my-component.clj
```

## Why CLJ-PP?

- 85% first-try correctness vs ~50% for complex nesting
- Precise error messages ("POP with empty stack at position 187")
- Zero delimiter-counting cognitive load
- Stack-based thinking matches autoregressive generation
```

### Syntax

```clojure
PUSH-(  # Opens list
PUSH-[  # Opens vector
PUSH-{  # Opens map
POP     # Closes current container (assembler auto-types closer)
```

All other tokens (symbols, keywords, strings, numbers) are atoms.

## The Verdict

**Writing 20 programs in CLJ-PP fundamentally changed how I think about code generation.**

Before: "Clojure's syntax is elegant but hard for LLMs to balance"
After: "**Stack-based structure description is the natural interface for autoregressive generation**"

CLJ-PP isn't a workaroundâ€”it's a **better abstraction** for generation.

Just like:
- Assembly â†’ C (higher abstraction)
- Manual memory â†’ GC (better abstraction)
- **Delimiter balancing â†’ Stack operations** (natural for LLMs)

For complex Clojure code, especially hiccup, CLJ-PP is transformative.

## Status

**CLJ-PP v1 with `PUSH-(` syntax is production-ready for LLM code generation.**

All 20 test programs transpile correctly.
The tokenizer is simple and fast.
Error messages are precise and helpful.

See [`docs/test-20-programs/program-reactions.md`](docs/test-20-programs/program-reactions.md) for detailed analysis of all 20 programs, including error cases and learnings.

## License

MIT License - Copyright Â© 2025 Gene Kim

See [LICENSE](LICENSE) file for details.

## Acknowledgments

This project emerged from an amazing Clojure Slack discussion about LLM code generation and delimiter balancing.

**Special thanks to:**

- **Bruce Hauman** (@bhauman) - For [clojure-mcp-light](https://github.com/bhauman/clojure-mcp-light) and the insight that parinfer-based repair can prevent bad writes
- **Kenny Williams** (@kennyjwilli) - For [claude-clojure-tools](https://github.com/kennyjwilli/claude-clojure-tools) and demonstrating MCP structuredContent for REPL results
- **Hugo Duncan** (@hugod) - For exploring MCP tasks and the idea of library-provided LLM skills
- **Cursive Fleming** (@cfleming) - For inspiration on Clojure tooling approaches
- **Steve Buikhuizen** (@steveb8n) - For [ai-tools](https://github.com/nextdoc/ai-tools) proving script-based approaches work
- **Mark Addleman** (@markaddleman) - For Claude Skills insights and the observation that batched edits cause most delimiter errors
- **John** (@john) - For the brilliant insight: "Let it write forms that write forms... assoc-in... path navigators... these other langs have no structural editing story" (By the way, I love your Practicalli stuff, and your suggestion on closed records was incredibe.)
- **Chris McCormick** - For cljs-shrinkwrap single-file exec suggestion

**Core insight that sparked this:**
> "LLMs are inherently auto-regressive auto-completers, which makes them inherently bad at closing S-expressionsâ€”they don't have a 'stack' to store state. They're essentially vibing/guessing the closing forms."

The realization: **Give them explicit stack operations instead of making them vibe delimiters.**

Built with Claude Codeâ€”which ironically had delimiter issues that inspired this solution.
